### the random forest classifier is investigated here
### as an alternative tool for the secondary learning
##### features
f=matrix(-1, nrow=19, ncol=9);
f[1,]=c(23, 4, 0.17, 0.69, 0.21,   3.02, 0.88, 0.09, 0.83);
f[2,]=c(21, 1, 0.05, 0, 1.15,      3.44, 0.16, 0.14, 0.21);
f[3,]=c(46, 4, 0.09, 0.11, -0.21,  2.07, 0.81, 0, 0.83);
f[4,]=c(20, 3, 0.15, 0.74, 0.18,   2.63, 0.86, 0, 0.86);
f[5,]=c(25, 2, 0.08, 0.27, 0.03,   3.07, 0.96, 0.04, 0.96);
f[6,]=c(50, 2, 0.04, 0, 1.48,      6.94, 0.25, 0.02, 0.31);
f[7,]=c(16, 3, 0.19, 0.22, 0.78,   3.84, 0.92, 0.19, 0.97);
f[8,]=c(16, 2, 0.12, 0.88, 0.49,   2.86, 0.51, 0, 0.7);
f[9,]=c(11, 1, 0.09, 0.22, 0.63,   2.11, 0.99, 0.18, 1);  
f[10,]=c(11, 1, 0.09, 0, -1.89,    5.83, 0.49, 0.09, 1);
f[11,]=c(22, 1, 0.05, 0.7, -0.19,  2.09, 0.92, 0, 0.88);
f[12,]=c(18, 2, 0.11, 0.79, 0.21,  2.18, 0.91, 0.28, 0.98);
f[13,]=c(13, 1, 0.08, 0.88, 0.04,  2.17, 0, 0, 0.89);
f[14,]=c(19, 4, 0.21, 0.77, 0.42,  2.76, 0.94, 0.11, 0.98);
f[15,]=c(20, 2, 0.1, 0.37, 0.65,   3.07, 0.71, 0.05, 0.85);
f[16,]=c(18, 1, 0.06, 0.94, 0,     2.23, 0.84, 0, 0.84);
f[17,]=c(48, 3, 0.06, 0, 1.15,     6.19, 0.32, 0.06, 0.45);
f[18,]=c(47, 1, 0.02, 0, -1.36,    4.23, 0.04, 0, 0.47);
f[19,]=c(20, 2, 0.1, 0.26, 0.67,   3.37, 0.51, 0, 0.62);

y=c(1,2,1,3,2, 1,2,2,3,3, 1,3,3,1,2, 2,3,1,3);

library(MASS);
a=lda(y~f);
library(e1071);
a=svm(y~f)
library(randomForest);
yfactor=as.factor(y);
a=randomForest(f,yfactor);